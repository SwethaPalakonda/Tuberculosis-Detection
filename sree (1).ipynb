{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d42b3f8-3e28-4f0f-89c0-af085c79d813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3360 images belonging to 2 classes.\n",
      "Found 840 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the main dataset path (no separate val folder needed!)\n",
    "dataset_dir = r\"C:\\Users\\sweth\\OneDrive\\MajorProject\"\n",
    "\n",
    "# Data Augmentation & Preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  \n",
    "    validation_split=0.2  # 20% of images will be used for validation\n",
    ")\n",
    "\n",
    "# Load Training Data (80% of the dataset)\n",
    "train_data = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\"  # Training set (80%)\n",
    ")\n",
    "\n",
    "# Load Validation Data (20% of the dataset)\n",
    "val_data = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\"  # Validation set (20%)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba43407-a2c1-4b08-9d2e-b42db1a820de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3360 images belonging to 2 classes.\n",
      "Found 840 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweth\\.software\\MajorProject\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 756ms/step - accuracy: 0.9354 - loss: 0.1744 - val_accuracy: 0.9964 - val_loss: 0.0213\n",
      "Epoch 2/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 731ms/step - accuracy: 0.9947 - loss: 0.0175 - val_accuracy: 0.9952 - val_loss: 0.0102\n",
      "Epoch 3/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 758ms/step - accuracy: 0.9937 - loss: 0.0206 - val_accuracy: 0.9940 - val_loss: 0.0130\n",
      "Epoch 4/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 770ms/step - accuracy: 0.9998 - loss: 0.0051 - val_accuracy: 0.9976 - val_loss: 0.0063\n",
      "Epoch 5/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 773ms/step - accuracy: 0.9985 - loss: 0.0090 - val_accuracy: 0.9988 - val_loss: 0.0066\n",
      "Epoch 6/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 743ms/step - accuracy: 0.9978 - loss: 0.0055 - val_accuracy: 0.9881 - val_loss: 0.0350\n",
      "Epoch 7/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 774ms/step - accuracy: 0.9968 - loss: 0.0099 - val_accuracy: 0.9976 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 777ms/step - accuracy: 1.0000 - loss: 5.4210e-04 - val_accuracy: 0.9976 - val_loss: 0.0080\n",
      "Epoch 9/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 760ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9940 - val_loss: 0.0111\n",
      "Epoch 10/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 798ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9976 - val_loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Model training complete! Saved as tb_detection_mobilenetv2.h5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define dataset path\n",
    "dataset_dir = r\"C:\\Users\\sweth\\OneDrive\\MajorProject\"\n",
    "\n",
    "# Data Augmentation & Preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    validation_split=0.2  # 80% training, 20% validation\n",
    ")\n",
    "\n",
    "# Load Training Data\n",
    "train_data = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# Load Validation Data\n",
    "val_data = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Load Pretrained MobileNetV2 (without the top layer)\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze base model layers (to use pretrained features)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers for TB detection\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)  # Prevent overfitting\n",
    "output = Dense(1, activation=\"sigmoid\")(x)  # Binary classification (TB vs Normal)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10,  # You can increase epochs for better results\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"tb_detection_mobilenetv2.h5\")\n",
    "\n",
    "print(\"ðŸŽ‰ Model training complete! Saved as tb_detection_mobilenetv2.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56ba4c8-1fd3-4c66-8ef1-65011bb27965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button, Canvas, Frame\n",
    "\n",
    "# Load trained model\n",
    "model = tf.keras.models.load_model(\"tb_detection_mobilenetv2.h5\")\n",
    "\n",
    "# Set default image paths (update with actual paths)\n",
    "BG_IMAGE_MAIN = r\"C:\\Users\\sweth\\OneDrive\\MajorProject\\background(1).jpeg\"\n",
    "BG_IMAGE_PRED = r\"C:\\Users\\sweth\\OneDrive\\MajorProject\\bg-2(1).jpeg\"\n",
    "\n",
    "class TBDetectionApp:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"TB Detection System\")\n",
    "        self.root.geometry(\"900x600\")\n",
    "\n",
    "        # Load and display background image for main window\n",
    "        if os.path.exists(BG_IMAGE_MAIN):\n",
    "            self.bg_main = Image.open(BG_IMAGE_MAIN).resize((900, 600))\n",
    "            self.bg_main_photo = ImageTk.PhotoImage(self.bg_main)\n",
    "            \n",
    "            self.canvas = Canvas(self.root, width=900, height=600)\n",
    "            self.canvas.pack(fill=\"both\", expand=True)\n",
    "            self.canvas.create_image(0, 0, image=self.bg_main_photo, anchor=\"nw\")\n",
    "\n",
    "            # Prevent garbage collection\n",
    "            self.root.bg_main_photo = self.bg_main_photo\n",
    "        else:\n",
    "            print(\"Error: Background image for main window not found!\")\n",
    "\n",
    "        # Frame for buttons\n",
    "        frame = Frame(self.root, bg=\"white\", padx=20, pady=20)\n",
    "        frame.place(relx=0.5, rely=0.5, anchor=\"center\")\n",
    "\n",
    "        Label(frame, text=\"TB Detection System\", font=(\"Arial\", 20, \"bold\"), bg=\"white\", fg=\"#333\").pack(pady=20)\n",
    "        Button(frame, text=\"Predict TB\", command=self.open_prediction_window, font=(\"Arial\", 14),\n",
    "               bg=\"#4CAF50\", fg=\"white\", padx=20, pady=10).pack(pady=10)\n",
    "        Button(frame, text=\"Exit\", command=self.root.quit, font=(\"Arial\", 14),\n",
    "               bg=\"#f44336\", fg=\"white\", padx=20, pady=10).pack(pady=10)\n",
    "\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def open_prediction_window(self):\n",
    "        self.root.withdraw()  # Hide main window\n",
    "        self.pred_root = tk.Toplevel()\n",
    "        self.pred_root.title(\"TB Detection - Prediction\")\n",
    "        self.pred_root.geometry(\"900x600\")\n",
    "\n",
    "        # Load and display background image for second window\n",
    "        if os.path.exists(BG_IMAGE_PRED):\n",
    "            self.bg_pred = Image.open(BG_IMAGE_PRED).resize((900, 600))\n",
    "            self.bg_pred_photo = ImageTk.PhotoImage(self.bg_pred)\n",
    "            \n",
    "            self.canvas_pred = Canvas(self.pred_root, width=900, height=600)\n",
    "            self.canvas_pred.pack(fill=\"both\", expand=True)\n",
    "            self.canvas_pred.create_image(0, 0, image=self.bg_pred_photo, anchor=\"nw\")\n",
    "\n",
    "            # Prevent garbage collection\n",
    "            self.pred_root.bg_pred_photo = self.bg_pred_photo\n",
    "        else:\n",
    "            print(\"Error: Background image for second window not found!\")\n",
    "\n",
    "        # Frame for Upload & Prediction\n",
    "        frame = Frame(self.pred_root, bg=\"white\", padx=20, pady=20)\n",
    "        frame.place(relx=0.5, rely=0.5, anchor=\"center\")\n",
    "\n",
    "        Button(frame, text=\"Upload X-Ray\", command=self.predict_tb, font=(\"Arial\", 14),\n",
    "               bg=\"#4CAF50\", fg=\"white\", padx=20, pady=10).pack(pady=10)\n",
    "\n",
    "        self.image_label = Label(frame, bg=\"white\")\n",
    "        self.image_label.pack()\n",
    "\n",
    "        self.result_label = Label(frame, text=\"Prediction: \", font=(\"Arial\", 16, \"bold\"), bg=\"white\", fg=\"#333\")\n",
    "        self.result_label.pack(pady=20)\n",
    "\n",
    "        Button(frame, text=\"Back\", command=self.go_back, font=(\"Arial\", 14),\n",
    "               bg=\"#FFA500\", fg=\"white\", padx=20, pady=10).pack(pady=10)\n",
    "        Button(frame, text=\"Exit\", command=self.pred_root.destroy, font=(\"Arial\", 14),\n",
    "               bg=\"#f44336\", fg=\"white\", padx=20, pady=10).pack(pady=10)\n",
    "\n",
    "    def go_back(self):\n",
    "        self.pred_root.destroy()\n",
    "        self.root.deiconify()  # Show main window again\n",
    "\n",
    "    def predict_tb(self):\n",
    "        file_path = filedialog.askopenfilename(title=\"Select Chest X-Ray Image\",\n",
    "                                               filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "        if not file_path:\n",
    "            return\n",
    "\n",
    "        img = self.preprocess_image(file_path)\n",
    "        prediction = model.predict(img)\n",
    "        confidence = prediction[0][0] * 100\n",
    "\n",
    "        result_text = f\"TB Detected ({confidence:.2f}%)\" if prediction[0][0] > 0.5 else f\"Normal ({100 - confidence:.2f}%)\"\n",
    "        self.result_label.config(text=f\"Prediction: {result_text}\",\n",
    "                                 fg=\"#FF0000\" if prediction[0][0] > 0.5 else \"#008000\")\n",
    "\n",
    "        self.display_image(file_path)\n",
    "\n",
    "    def preprocess_image(self, img_path):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = img.resize((224, 224))\n",
    "        img = np.array(img) / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img\n",
    "\n",
    "    def display_image(self, img_path):\n",
    "        img = Image.open(img_path).resize((300, 300))\n",
    "        img = ImageTk.PhotoImage(img)\n",
    "        self.image_label.config(image=img)\n",
    "        self.image_label.image = img\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TBDetectionApp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba452e0-356f-4cf6-a186-f4faff6fb9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
